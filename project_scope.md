CH∆Ø∆†NG 3: TRI·ªÇN KHAI CHI TI·∫æT ·ª®NG D·ª§NG

3.1. L·ª±a ch·ªçn v√† thi·∫øt k·∫ø ki·∫øn tr√∫c m√¥ h√¨nh (CNN)
Sau khi ƒë√£ ph√¢n t√≠ch v√† ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu ·ªü Ch∆∞∆°ng 2, b∆∞·ªõc ti·∫øp theo l√† x√¢y d·ª±ng m·ªôt m√¥ h√¨nh h·ªçc m√°y c√≥ kh·∫£ nƒÉng h·ªçc ƒë∆∞·ª£c c√°c ƒë·∫∑c tr∆∞ng (features) t·ª´ d·ªØ li·ªáu ·∫£nh 150x150 pixel ƒë·ªÉ ph√¢n lo·∫°i ch√∫ng v√†o 2 l·ªõp (Cat v√† Dog).

L·ª±a ch·ªçn ki·∫øn tr√∫c: ƒê·ªëi v·ªõi c√°c b√†i to√°n th·ªã gi√°c m√°y t√≠nh v√† nh·∫≠n d·∫°ng h√¨nh ·∫£nh, ƒë·∫∑c bi·ªát l√† ph√¢n lo·∫°i ·∫£nh ƒë·ªông v·∫≠t, M·∫°ng n∆°-ron T√≠ch ch·∫≠p (Convolutional Neural Network - CNN) ƒë√£ ƒë∆∞·ª£c ch·ª©ng minh l√† ki·∫øn tr√∫c hi·ªáu qu·∫£ v√† m·∫°nh m·∫Ω nh·∫•t. Kh√¥ng gi·ªëng nh∆∞ c√°c m·∫°ng n∆°-ron truy·ªÅn th·ªëng, CNN c√≥ kh·∫£ nƒÉng t·ª± ƒë·ªông h·ªçc v√† tr√≠ch xu·∫•t c√°c ƒë·∫∑c tr∆∞ng kh√¥ng gian (spatial features) t·ª´ ·∫£nh, ch·∫≥ng h·∫°n nh∆∞ c·∫°nh, g√≥c, h√¨nh d·∫°ng m·∫Øt, tai, m≈©i, v√† c√°c ƒë·∫∑c ƒëi·ªÉm ƒë·∫∑c tr∆∞ng c·ªßa ch√≥ v√† m√®o th√¥ng qua c√°c b·ªô l·ªçc (convolutional filters).

Thi·∫øt k·∫ø ki·∫øn tr√∫c m√¥ h√¨nh: D·ª±a tr√™n c√°c th·ª±c ti·ªÖn t·ªët nh·∫•t cho b√†i to√°n ph√¢n lo·∫°i ·∫£nh nh·ªã ph√¢n (binary classification), nh√≥m ƒë√£ thi·∫øt k·∫ø m·ªôt ki·∫øn tr√∫c CNN tu·∫ßn t·ª± (Sequential) s·ª≠ d·ª•ng Keras. M√¥ h√¨nh n√†y bao g·ªìm c√°c kh·ªëi (block) t√≠ch ch·∫≠p v√† c√°c l·ªõp k·∫øt n·ªëi ƒë·∫ßy ƒë·ªß (fully-connected) ƒë·ªÉ th·ª±c hi·ªán ph√¢n lo·∫°i:
‚Ä¢	Kh·ªëi T√≠ch ch·∫≠p 1: Bao g·ªìm l·ªõp Conv2D v·ªõi 32 b·ªô l·ªçc (filters) k√≠ch th∆∞·ªõc 3x3 ƒë·ªÉ h·ªçc c√°c ƒë·∫∑c tr∆∞ng c∆° b·∫£n nh∆∞ c·∫°nh v√† ƒë∆∞·ªùng n√©t, theo sau l√† m·ªôt l·ªõp MaxPooling2D (2x2) ƒë·ªÉ gi·∫£m chi·ªÅu d·ªØ li·ªáu v√† tƒÉng t√≠nh b·∫•t bi·∫øn.
‚Ä¢	Kh·ªëi T√≠ch ch·∫≠p 2: Bao g·ªìm l·ªõp Conv2D v·ªõi 64 b·ªô l·ªçc ƒë·ªÉ h·ªçc c√°c ƒë·∫∑c tr∆∞ng ph·ª©c t·∫°p h∆°n, theo sau l√† MaxPooling2D (2x2).
‚Ä¢	Kh·ªëi T√≠ch ch·∫≠p 3: Bao g·ªìm l·ªõp Conv2D v·ªõi 128 b·ªô l·ªçc ƒë·ªÉ h·ªçc c√°c ƒë·∫∑c tr∆∞ng chi ti·∫øt v√† ph·ª©c t·∫°p, theo sau l√† MaxPooling2D (2x2).
‚Ä¢	Kh·ªëi T√≠ch ch·∫≠p 4: Ti·∫øp t·ª•c v·ªõi l·ªõp Conv2D 128 b·ªô l·ªçc ƒë·ªÉ tinh ch·ªânh c√°c ƒë·∫∑c tr∆∞ng, theo sau l√† MaxPooling2D (2x2).
‚Ä¢	Kh·ªëi Ph√¢n lo·∫°i: L·ªõp Flatten ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ "l√†m ph·∫≥ng" d·ªØ li·ªáu 2D t·ª´ kh·ªëi t√≠ch ch·∫≠p th√†nh m·ªôt vector 1D. Vector n√†y sau ƒë√≥ ƒë∆∞·ª£c ƒë∆∞a qua m·ªôt l·ªõp Dropout (50%) ƒë·ªÉ gi·∫£m thi·ªÉu hi·ªán t∆∞·ª£ng h·ªçc v·∫πt (overfitting), ti·∫øp theo l√† l·ªõp Dense (512 n∆°-ron) v·ªõi h√†m k√≠ch ho·∫°t ReLU v√† cu·ªëi c√πng l√† l·ªõp Dense (2 n∆°-ron) v·ªõi h√†m k√≠ch ho·∫°t softmax ƒë·ªÉ ƒë∆∞a ra x√°c su·∫•t ph√¢n lo·∫°i cho 2 l·ªõp (Cat v√† Dog).
‚Ä¢	T·ªëi ∆∞u h√≥a: M√¥ h√¨nh s·ª≠ d·ª•ng Adam optimizer v·ªõi h√†m m·∫•t m√°t categorical_crossentropy v√¨ nh√£n (labels) c·ªßa ch√∫ng ta ƒë∆∞·ª£c m√£ h√≥a d∆∞·ªõi d·∫°ng one-hot encoding.

X√¢y d·ª±ng ki·∫øn tr√∫c m√¥ h√¨nh (CNN)
# Define the CNN architecture
model = keras.Sequential([
    # Input layer
    layers.Input(shape=(150, 150, 3)),
    
    # Convolutional Block 1
    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D(2, 2),
    
    # Convolutional Block 2
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D(2, 2),
    
    # Convolutional Block 3
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D(2, 2),
    
    # Convolutional Block 4
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D(2, 2),
    
    # Classification Block
    layers.Flatten(),
    layers.Dropout(0.5),
    layers.Dense(512, activation='relu'),
    layers.Dense(2, activation='softmax')
])

# Compile the model
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

3.2. Hu·∫•n luy·ªán v√† tinh ch·ªânh m√¥ h√¨nh (S·ª≠ d·ª•ng cat_dog_model_v2_final.h5)
TƒÉng c∆∞·ªùng d·ªØ li·ªáu (Data Augmentation)
ƒê·ªÉ gi√∫p m√¥ h√¨nh c√≥ kh·∫£ nƒÉng t·ªïng qu√°t h√≥a t·ªët h∆°n v√† gi·∫£m thi·ªÉu h·ªçc v·∫πt (overfitting), ƒë·∫∑c bi·ªát quan tr·ªçng v·ªõi d·ªØ li·ªáu ·∫£nh ƒë·ªông v·∫≠t c√≥ nhi·ªÅu bi·∫øn th·ªÉ v·ªÅ g√≥c ch·ª•p, √°nh s√°ng, v√† v·ªã tr√≠, ch√∫ng ta s·ª≠ d·ª•ng k·ªπ thu·∫≠t TƒÉng c∆∞·ªùng d·ªØ li·ªáu. K·ªπ thu·∫≠t n√†y s·∫Ω t·∫°o ra c√°c phi√™n b·∫£n m·ªõi, h∆°i kh√°c bi·ªát c·ªßa ·∫£nh hu·∫•n luy·ªán trong m·ªói k·ª∑ nguy√™n (epoch) b·∫±ng c√°ch √°p d·ª•ng c√°c ph√©p bi·∫øn ƒë·ªïi ng·∫´u nhi√™n nh∆∞ xoay, d·ªãch chuy·ªÉn, zoom, c·∫Øt x√©n, v√† l·∫≠t ngang ·∫£nh.

TƒÉng c∆∞·ªùng d·ªØ li·ªáu
# DATA AUGMENTATION cho training
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=40,          # Xoay ·∫£nh trong kho·∫£ng ¬±40 ƒë·ªô
    width_shift_range=0.2,      # D·ªãch chuy·ªÉn ngang 20%
    height_shift_range=0.2,     # D·ªãch chuy·ªÉn d·ªçc 20%
    shear_range=0.2,            # Bi·∫øn d·∫°ng c·∫Øt 20%
    zoom_range=0.2,             # Zoom 20%
    horizontal_flip=True,       # L·∫≠t ngang ·∫£nh
    fill_mode='nearest'         # ƒêi·ªÅn pixel b·∫±ng ph∆∞∆°ng ph√°p nearest
)

# Ch·ªâ rescale cho validation (kh√¥ng augmentation)
validation_datagen = ImageDataGenerator(rescale=1./255)

# T·∫°o generators t·ª´ th∆∞ m·ª•c
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='categorical'
)

validation_generator = validation_datagen.flow_from_directory(
    validation_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='categorical'
)

Bi√™n d·ªãch m√¥ h√¨nh (Compiling)
Tr∆∞·ªõc khi hu·∫•n luy·ªán, m√¥ h√¨nh c·∫ßn ƒë∆∞·ª£c bi√™n d·ªãch v·ªõi c√°c th√†nh ph·∫ßn sau:
‚Ä¢	H√†m t·ªëi ∆∞u (Optimizer): Ch√∫ng ta s·ª≠ d·ª•ng adam, m·ªôt thu·∫≠t to√°n t·ªëi ∆∞u hi·ªáu qu·∫£ v√† ph·ªï bi·∫øn, gi√∫p ƒëi·ªÅu ch·ªânh t·ªëc ƒë·ªô h·ªçc (learning rate) m·ªôt c√°ch th√≠ch ·ª©ng, ƒë·∫∑c bi·ªát ph√π h·ª£p v·ªõi b√†i to√°n ph√¢n lo·∫°i ·∫£nh.
‚Ä¢	H√†m m·∫•t m√°t (Loss Function): categorical_crossentropy ƒë∆∞·ª£c ch·ªçn v√¨ ƒë√¢y l√† b√†i to√°n ph√¢n lo·∫°i ƒëa l·ªõp (2 l·ªõp) v√† c√°c nh√£n (labels) c·ªßa ch√∫ng ta ƒë∆∞·ª£c m√£ h√≥a d∆∞·ªõi d·∫°ng one-hot vector (v√≠ d·ª•: [1, 0] cho Cat, [0, 1] cho Dog).
‚Ä¢	Ch·ªâ s·ªë ƒë√°nh gi√° (Metrics): Ch√∫ng ta theo d√µi ch·ªâ s·ªë accuracy (ƒë·ªô ch√≠nh x√°c) trong su·ªët qu√° tr√¨nh hu·∫•n luy·ªán ƒë·ªÉ ƒë√°nh gi√° hi·ªáu su·∫•t m√¥ h√¨nh.

Bi√™n d·ªãch m√¥ h√¨nh
# Compile the CNN model
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

S·ª≠ d·ª•ng Callbacks ƒë·ªÉ tinh ch·ªânh
Callbacks l√† c√°c h√†m ƒë∆∞·ª£c g·ªçi t·∫°i c√°c th·ªùi ƒëi·ªÉm kh√°c nhau trong qu√° tr√¨nh hu·∫•n luy·ªán, cho ph√©p ch√∫ng ta t·ª± ƒë·ªông h√≥a vi·ªác tinh ch·ªânh m√¥ h√¨nh:
‚Ä¢	ModelCheckpoint: ƒê√¢y l√† callback quan tr·ªçng nh·∫•t. N√≥ s·∫Ω theo d√µi val_accuracy (accuracy tr√™n t·∫≠p validation) v√† l∆∞u l·∫°i phi√™n b·∫£n t·ªët nh·∫•t c·ªßa m√¥ h√¨nh v√†o t·ªáp cat_dog_model.h5. ƒê√¢y ch√≠nh l√† t·ªáp m√¥ h√¨nh m√† sau n√†y ch√∫ng ta s·ª≠ d·ª•ng trong ·ª©ng d·ª•ng web Flask.
‚Ä¢	EarlyStopping: Theo d√µi val_loss (loss tr√™n t·∫≠p validation). N·∫øu val_loss kh√¥ng c·∫£i thi·ªán sau 10 epochs (patience=10), qu√° tr√¨nh hu·∫•n luy·ªán s·∫Ω t·ª± ƒë·ªông d·ª´ng l·∫°i v√† kh√¥i ph·ª•c weights t·ªët nh·∫•t (restore_best_weights=True) ƒë·ªÉ tr√°nh overfitting.
‚Ä¢	ReduceLROnPlateau: N·∫øu val_loss kh√¥ng c·∫£i thi·ªán sau 5 epochs (patience=5), t·ªëc ƒë·ªô h·ªçc s·∫Ω ƒë∆∞·ª£c gi·∫£m ƒëi m·ªôt n·ª≠a (factor=0.5) v·ªõi learning rate t·ªëi thi·ªÉu l√† 1e-7 ƒë·ªÉ gi√∫p m√¥ h√¨nh "t√¨m ƒë∆∞·ªùng" t·ªët h∆°n trong qu√° tr√¨nh t·ªëi ∆∞u.

callbacks = [
    ModelCheckpoint(
        'models/cat_dog_model.h5',
        monitor='val_accuracy',
        save_best_only=True,
        verbose=1
    ),
    EarlyStopping(
        monitor='val_loss',
        patience=10,
        restore_best_weights=True,
        verbose=1
    ),
    ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.5,
        patience=5,
        min_lr=1e-7,
        verbose=1
    )
]

Hu·∫•n luy·ªán m√¥ h√¨nh (Training)
Qu√° tr√¨nh hu·∫•n luy·ªán s·ª≠ d·ª•ng data generator ƒë·ªÉ load ·∫£nh t·ª´ th∆∞ m·ª•c m·ªôt c√°ch t·ª± ƒë·ªông, √°p d·ª•ng augmentation cho t·∫≠p training v√† ch·ªâ rescale cho t·∫≠p validation. M√¥ h√¨nh ƒë∆∞·ª£c hu·∫•n luy·ªán v·ªõi s·ªë epochs m·∫∑c ƒë·ªãnh l√† 50, batch_size l√† 32. Sau khi ho√†n th√†nh, m√¥ h√¨nh t·ªët nh·∫•t ƒë∆∞·ª£c l∆∞u v√† ƒë·ªì th·ªã training history (accuracy v√† loss) ƒë∆∞·ª£c v·∫Ω v√† l∆∞u l·∫°i ƒë·ªÉ ph√¢n t√≠ch.

steps_per_epoch = max(1, train_gen.samples // batch_size)
history = model.fit(
    train_gen,
    steps_per_epoch=steps_per_epoch,
    epochs=50,
    validation_data=val_gen,
    validation_steps=val_gen.samples // batch_size,
    callbacks=callbacks,
    verbose=1
)

# L∆∞u model cu·ªëi c√πng
model.save('models/cat_dog_model_final.h5')

# V·∫Ω v√† l∆∞u ƒë·ªì th·ªã training history
plot_training_history(history, 'models')

3.3. Bi·ªÉu di·ªÖn v√† ƒë√°nh gi√° k·∫øt qu·∫£ m√¥ h√¨nh

3.3.1. C√°c ch·ªâ s·ªë ƒë√°nh gi√° (Evaluation Metrics: Accuracy, Precision, Recall, F1-Score)
ƒê·ªÉ ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng m√¥ h√¨nh m·ªôt c√°ch to√†n di·ªán, ch√∫ng ta s·ª≠ d·ª•ng c√°c ch·ªâ s·ªë ƒë√°nh gi√° chu·∫©n trong h·ªçc m√°y:
‚Ä¢	Accuracy (ƒê·ªô ch√≠nh x√°c): T·ª∑ l·ªá s·ªë d·ª± ƒëo√°n ƒë√∫ng tr√™n t·ªïng s·ªë d·ª± ƒëo√°n. ƒê√¢y l√† ch·ªâ s·ªë t·ªïng qu√°t nh·∫•t, nh∆∞ng c√≥ th·ªÉ kh√¥ng ph·∫£n √°nh ƒë√∫ng hi·ªáu su·∫•t khi d·ªØ li·ªáu m·∫•t c√¢n b·∫±ng.
‚Ä¢	Precision (ƒê·ªô ch√≠nh x√°c d·ª± ƒëo√°n): T·ª∑ l·ªá s·ªë d·ª± ƒëo√°n d∆∞∆°ng t√≠nh th·ª±c s·ª± trong t·∫•t c·∫£ c√°c d·ª± ƒëo√°n d∆∞∆°ng t√≠nh. Precision = TP / (TP + FP), trong ƒë√≥ TP l√† True Positive v√† FP l√† False Positive.
‚Ä¢	Recall (ƒê·ªô nh·∫°y): T·ª∑ l·ªá s·ªë d·ª± ƒëo√°n d∆∞∆°ng t√≠nh th·ª±c s·ª± trong t·∫•t c·∫£ c√°c tr∆∞·ªùng h·ª£p th·ª±c s·ª± d∆∞∆°ng t√≠nh. Recall = TP / (TP + FN), trong ƒë√≥ FN l√† False Negative. Recall cho bi·∫øt kh·∫£ nƒÉng m√¥ h√¨nh ph√°t hi·ªán ƒë∆∞·ª£c c√°c tr∆∞·ªùng h·ª£p th·ª±c s·ª± l√† Cat ho·∫∑c Dog.
‚Ä¢	F1-Score: Trung b√¨nh ƒëi·ªÅu h√≤a gi·ªØa Precision v√† Recall, gi√∫p c√¢n b·∫±ng gi·ªØa hai ch·ªâ s·ªë n√†y. F1-Score = 2 √ó (Precision √ó Recall) / (Precision + Recall).

ƒê√°nh gi√° m√¥ h√¨nh v·ªõi c√°c ch·ªâ s·ªë
# ƒê√°nh gi√° model tr√™n t·∫≠p validation
model = load_model('models/cat_dog_model_v2_final.h5')

# T·∫°o generator cho validation (kh√¥ng shuffle ƒë·ªÉ gi·ªØ th·ª© t·ª± nh√£n)
datagen = ImageDataGenerator(rescale=1.0 / 255)
generator = datagen.flow_from_directory(
    validation_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='categorical',
    shuffle=False  # Quan tr·ªçng ƒë·ªÉ mapping ƒë√∫ng v·ªõi predictions
)

# Predict to√†n b·ªô validation set
predictions = model.predict(generator, verbose=1)
y_true = generator.classes
y_pred = np.argmax(predictions, axis=1)

# T√≠nh c√°c ch·ªâ s·ªë ƒë√°nh gi√°
from sklearn.metrics import classification_report

class_indices = generator.class_indices
idx_to_class = {idx: name for name, idx in class_indices.items()}
class_names = [idx_to_class[idx] for idx in sorted(idx_to_class.keys())]

# In b√°o c√°o ph√¢n lo·∫°i chi ti·∫øt
report_text = classification_report(
    y_true,
    y_pred,
    target_names=class_names,
    digits=4,
    zero_division=0
)
print(report_text)

3.3.2. Tr·ª±c quan h√≥a k·∫øt qu·∫£ (Ma tr·∫≠n nh·∫ßm l·∫´n - Confusion Matrix)
Ma tr·∫≠n nh·∫ßm l·∫´n (Confusion Matrix) l√† m·ªôt c√¥ng c·ª• tr·ª±c quan h√≥a quan tr·ªçng ƒë·ªÉ hi·ªÉu r√µ h∆°n v·ªÅ hi·ªáu su·∫•t m√¥ h√¨nh. Ma tr·∫≠n n√†y cho bi·∫øt s·ªë l∆∞·ª£ng d·ª± ƒëo√°n ƒë√∫ng v√† sai cho t·ª´ng l·ªõp, gi√∫p x√°c ƒë·ªãnh m√¥ h√¨nh nh·∫ßm l·∫´n gi·ªØa c√°c l·ªõp nh∆∞ th·∫ø n√†o. ƒê·ªëi v·ªõi b√†i to√°n ph√¢n lo·∫°i Cat/Dog, ma tr·∫≠n nh·∫ßm l·∫´n c√≥ d·∫°ng 2x2:

```
                Predicted: Cat    Predicted: Dog
Actual: Cat     TP (True Positive)  FN (False Negative)
Actual: Dog     FP (False Positive) TN (True Negative)
```

Trong ƒë√≥:
‚Ä¢	TP (True Positive): S·ªë l∆∞·ª£ng ·∫£nh Cat ƒë∆∞·ª£c d·ª± ƒëo√°n ƒë√∫ng l√† Cat.
‚Ä¢	FN (False Negative): S·ªë l∆∞·ª£ng ·∫£nh Cat b·ªã d·ª± ƒëo√°n sai l√† Dog.
‚Ä¢	FP (False Positive): S·ªë l∆∞·ª£ng ·∫£nh Dog b·ªã d·ª± ƒëo√°n sai l√† Cat.
‚Ä¢	TN (True Negative): S·ªë l∆∞·ª£ng ·∫£nh Dog ƒë∆∞·ª£c d·ª± ƒëo√°n ƒë√∫ng l√† Dog.

V·∫Ω Ma tr·∫≠n nh·∫ßm l·∫´n
# V·∫Ω Confusion Matrix
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

cm = confusion_matrix(y_true, y_pred)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=class_names, yticklabels=class_names)
plt.title('Confusion Matrix - Cat/Dog Classification')
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.savefig('models/confusion_matrix.png', dpi=150)
plt.close()

3.3.3. Code v√† Output ƒë√°nh gi√° tr√™n t·∫≠p Test
Script ƒë√°nh gi√° ho√†n ch·ªânh s·ª≠ d·ª•ng sklearn.metrics ƒë·ªÉ t√≠nh to√°n v√† in ra c√°c ch·ªâ s·ªë ƒë√°nh gi√° chi ti·∫øt tr√™n t·∫≠p validation/test. Output bao g·ªìm Precision, Recall, F1-Score cho t·ª´ng l·ªõp (Cat v√† Dog), c√πng v·ªõi Macro Average v√† Weighted Average.

Code ƒë√°nh gi√° tr√™n t·∫≠p Test
# File: evaluate_model.py
def evaluate_model(model_path='models/cat_dog_model_v2_final.h5', 
                   data_dir='data', batch_size=32, img_size=(150, 150)):
    """ƒê√°nh gi√° model v√† in k·∫øt qu·∫£ ra terminal."""
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y model t·∫°i: {model_path}")
    
    print("=" * 60)
    print("ƒêANG ƒê√ÅNH GI√Å MODEL CAT/DOG")
    print("=" * 60)
    print(f"Model: {model_path}")
    print(f"Data dir: {data_dir}")
    
    # T·∫°o generator cho validation
    generator = load_validation_generator(data_dir, img_size=img_size, batch_size=batch_size)
    if generator.samples == 0:
        raise ValueError("Kh√¥ng c√≥ m·∫´u validation n√†o ƒë·ªÉ ƒë√°nh gi√°.")
    
    # Load model v√† predict
    model = load_model(model_path)
    predictions = model.predict(generator, verbose=1)
    y_true = generator.classes
    y_pred = np.argmax(predictions, axis=1)
    
    # Mapping class names
    class_indices = generator.class_indices
    idx_to_class = {idx: name for name, idx in class_indices.items()}
    class_names = [idx_to_class[idx] for idx in sorted(idx_to_class.keys())]
    
    # In b√°o c√°o ph√¢n lo·∫°i
    report_text = classification_report(
        y_true, y_pred,
        target_names=class_names,
        digits=4,
        zero_division=0
    )
    
    print("\nB·∫¢NG B√ÅO C√ÅO PH√ÇN LO·∫†I (t∆∞∆°ng t·ª± Colab sklearn):\n")
    print(report_text)
    print("=" * 60)

Output m·∫´u ƒë√°nh gi√°
```
              precision    recall  f1-score   support
        cats     0.8276    0.7676    0.7965      1601
        dogs     0.7832    0.8400    0.8106      1600

    accuracy                         0.8038      3201
   macro avg     0.8054    0.8038    0.8036      3201
weighted avg     0.8054    0.8038    0.8036      3201
```

3.4. T√≠ch h·ª£p m√¥ h√¨nh v√†o m√°y ch·ªß Backend (Flask API)

3.4.1. T·∫£i m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán (load_model)
Tr∆∞·ªõc khi c√≥ th·ªÉ s·ª≠ d·ª•ng m√¥ h√¨nh ƒë·ªÉ d·ª± ƒëo√°n, ch√∫ng ta c·∫ßn load m√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán t·ª´ file ƒë√£ l∆∞u. Trong ·ª©ng d·ª•ng Flask, ch√∫ng ta load m√¥ h√¨nh m·ªôt l·∫ßn khi kh·ªüi ƒë·ªông ·ª©ng d·ª•ng (singleton pattern) ƒë·ªÉ tr√°nh ph·∫£i load l·∫°i nhi·ªÅu l·∫ßn cho m·ªói request, gi√∫p tƒÉng hi·ªáu su·∫•t.

T·∫£i m√¥ h√¨nh khi kh·ªüi ƒë·ªông Flask
# File: app_flask.py
from tensorflow.keras.models import load_model
import os

MODEL_PATH = 'models/cat_dog_model_v2_final.h5'
model = None

def load_model_once():
    """Load model khi start app - ch·ªâ load m·ªôt l·∫ßn"""
    global model
    if model is None:
        if os.path.exists(MODEL_PATH):
            try:
                model = load_model(MODEL_PATH)
                print(f"Model loaded from {MODEL_PATH}")
                return model
            except Exception as e:
                print(f"Error loading {MODEL_PATH}: {e}")
        else:
            print(f"Warning: Model not found at {MODEL_PATH}")
    return model

# Load model khi start app
if __name__ == '__main__':
    load_model_once()
    app.run(debug=True, host='0.0.0.0', port=5000)

3.4.2. X√¢y d·ª±ng API d·ª± ƒëo√°n (/predict)
API endpoint `/predict` nh·∫≠n file ·∫£nh t·ª´ client (t·ªëi ƒëa 6 ·∫£nh m·ªói l·∫ßn), ti·ªÅn x·ª≠ l√Ω ·∫£nh (resize v·ªÅ 150x150, chu·∫©n h√≥a pixel v·ªÅ [0,1]), sau ƒë√≥ s·ª≠ d·ª•ng m√¥ h√¨nh ƒë√£ load ƒë·ªÉ d·ª± ƒëo√°n. K·∫øt qu·∫£ ƒë∆∞·ª£c tr·∫£ v·ªÅ d∆∞·ªõi d·∫°ng JSON bao g·ªìm t√™n file, l·ªõp d·ª± ƒëo√°n (Cat ho·∫∑c Dog), ƒë·ªô tin c·∫≠y (confidence), v√† chi ti·∫øt x√°c su·∫•t cho t·ª´ng l·ªõp.

API endpoint d·ª± ƒëo√°n
# File: app_flask.py
from flask import Flask, request, jsonify
from PIL import Image
from tensorflow.keras.preprocessing import image
import numpy as np

app = Flask(__name__)
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB max
app.config['ALLOWED_EXTENSIONS'] = {'png', 'jpg', 'jpeg'}

def preprocess_image(img):
    """Preprocess ·∫£nh ƒë·ªÉ predict"""
    if img.mode != 'RGB':
        img = img.convert('RGB')
    img = img.resize((150, 150))  # Resize v·ªÅ k√≠ch th∆∞·ªõc input c·ªßa model
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)  # Th√™m batch dimension
    img_array = img_array / 255.0  # Chu·∫©n h√≥a v·ªÅ [0, 1]
    return img_array

@app.route('/predict', methods=['POST'])
def predict():
    """API endpoint ƒë·ªÉ predict t·ªëi ƒëa 6 ·∫£nh"""
    try:
        files = []
        if 'files' in request.files:
            files = request.files.getlist('files')
        elif 'file' in request.files:
            files = request.files.getlist('file')
        
        files = [f for f in files if f and f.filename]
        
        if not files:
            return jsonify({'error': 'No file selected'}), 400
        
        if len(files) > 6:
            return jsonify({'error': 'Ch·ªâ h·ªó tr·ª£ t·ªëi ƒëa 6 ·∫£nh m·ªói l·∫ßn'}), 400
        
        model = load_model_once()
        if model is None:
            return jsonify({'error': 'Model not found'}), 500
        
        # X·ª≠ l√Ω batch: preprocess v√† predict c√πng l√∫c
        batch_data = []
        file_names = []
        for idx, file in enumerate(files, start=1):
            img = Image.open(file.stream)
            img_array = preprocess_image(img)
            batch_data.append(img_array)
            file_names.append(file.filename or f'image_{idx}.png')
        
        # Predict batch
        batch_input = np.vstack(batch_data)
        predictions = model.predict(batch_input, verbose=0)
        class_names = ['cat', 'dog']
        
        # Format k·∫øt qu·∫£
        results = []
        for name, probs in zip(file_names, predictions):
            predicted_class_idx = int(np.argmax(probs))
            confidence = float(probs[predicted_class_idx])
            results.append({
                'filename': name,
                'class': class_names[predicted_class_idx],
                'confidence': round(confidence * 100, 2),
                'details': {
                    'cat': round(float(probs[0]) * 100, 2),
                    'dog': round(float(probs[1]) * 100, 2)
                }
            })
        
        return jsonify({'results': results})
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500

3.5. X√¢y d·ª±ng giao di·ªán tr·ª±c quan h√≥a (Frontend)

3.5.1. Thu th·∫≠p d·ªØ li·ªáu t·∫£i l√™n (Upload)
Frontend ƒë∆∞·ª£c x√¢y d·ª±ng ƒë·ªÉ cho ph√©p ng∆∞·ªùi d√πng upload ·∫£nh ch√≥ ho·∫∑c m√®o v√† nh·∫≠n ƒë∆∞·ª£c k·∫øt qu·∫£ d·ª± ƒëo√°n ngay l·∫≠p t·ª©c. H·ªá th·ªëng h·ªó tr·ª£ upload nhi·ªÅu file ·∫£nh c√πng l√∫c (t·ªëi ƒëa 6 ·∫£nh) th√¥ng qua input file HTML v·ªõi thu·ªôc t√≠nh `multiple`. ƒê·ªÉ c·∫£i thi·ªán tr·∫£i nghi·ªám ng∆∞·ªùi d√πng, khi ng∆∞·ªùi d√πng ch·ªçn file, ·∫£nh ƒë∆∞·ª£c preview ngay l·∫≠p t·ª©c b·∫±ng FileReader API m√† kh√¥ng c·∫ßn upload l√™n server, gi√∫p ng∆∞·ªùi d√πng x√°c nh·∫≠n v√† ki·ªÉm tra ·∫£nh tr∆∞·ªõc khi g·ª≠i request d·ª± ƒëo√°n.

C√°c t√≠nh nƒÉng c·ªßa ph·∫ßn upload:
‚Ä¢	Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng: T·ªëi ƒëa 6 ·∫£nh m·ªói l·∫ßn ƒë·ªÉ ƒë·∫£m b·∫£o hi·ªáu su·∫•t x·ª≠ l√Ω t·ªët.
‚Ä¢	Validation ƒë·ªãnh d·∫°ng: Ch·ªâ ch·∫•p nh·∫≠n c√°c ƒë·ªãnh d·∫°ng ·∫£nh ph·ªï bi·∫øn (PNG, JPG, JPEG).
‚Ä¢	Gi·ªõi h·∫°n k√≠ch th∆∞·ªõc: M·ªói file t·ªëi ƒëa 16MB ƒë·ªÉ tr√°nh qu√° t·∫£i server.
‚Ä¢	Preview real-time: Hi·ªÉn th·ªã preview ·∫£nh ngay khi ch·ªçn, kh√¥ng c·∫ßn upload.
‚Ä¢	Giao di·ªán th√¢n thi·ªán: S·ª≠ d·ª•ng drag-and-drop area v·ªõi thi·∫øt k·∫ø tr·ª±c quan.

Thu th·∫≠p d·ªØ li·ªáu upload
<!-- File: templates/index.html -->
<div class="upload-area" onclick="document.getElementById('fileInput').click()">
    <p style="font-size: 18px; margin-bottom: 10px;">üì§ Click ƒë·ªÉ ch·ªçn ·∫£nh</p>
    <p style="color: #666; font-size: 14px;">PNG, JPG, JPEG (t·ªëi ƒëa 6 ·∫£nh, 16MB/·∫£nh)</p>
    <input type="file" id="fileInput" accept="image/png,image/jpeg,image/jpg" multiple>
</div>

<script>
    const fileInput = document.getElementById('fileInput');
    const previewsContainer = document.getElementById('previewsContainer');
    let selectedFiles = [];
    
    fileInput.addEventListener('change', function(e) {
        selectedFiles = Array.from(e.target.files).slice(0, 6);
        
        if (e.target.files.length > 6) {
            alert('Ch·ªâ ch·ªçn t·ªëi ƒëa 6 ·∫£nh, h·ªá th·ªëng ƒë√£ l·∫•y 6 ·∫£nh ƒë·∫ßu ti√™n.');
        }
        
        // Preview ·∫£nh ƒë√£ ch·ªçn
        previewsContainer.innerHTML = '';
        selectedFiles.forEach((file, idx) => {
            const previewCard = document.createElement('div');
            previewCard.className = 'preview-card';
            previewCard.innerHTML = `
                <img class="preview-image" alt="Preview ${idx + 1}">
                <div class="preview-name">${file.name}</div>
            `;
            previewsContainer.appendChild(previewCard);
            
            const reader = new FileReader();
            reader.onload = (event) => {
                previewCard.querySelector('.preview-image').src = event.target.result;
            };
            reader.readAsDataURL(file);
        });
        
        // K√≠ch ho·∫°t n√∫t Predict
        document.getElementById('predictBtn').disabled = selectedFiles.length === 0;
    });
</script>

3.5.2. G·ª≠i request d·ª± ƒëo√°n v√† x·ª≠ l√Ω ph·∫£n h·ªìi
Sau khi ng∆∞·ªùi d√πng ch·ªçn ·∫£nh v√† nh·∫•n n√∫t "Ph√¢n T√≠ch", frontend s·∫Ω t·∫°o FormData ch·ª©a c√°c file ·∫£nh ƒë√£ ch·ªçn v√† g·ª≠i POST request ƒë·∫øn endpoint `/predict` c·ªßa Flask backend. Trong qu√° tr√¨nh x·ª≠ l√Ω, m·ªôt spinner loading ƒë∆∞·ª£c hi·ªÉn th·ªã ƒë·ªÉ th√¥ng b√°o cho ng∆∞·ªùi d√πng bi·∫øt h·ªá th·ªëng ƒëang x·ª≠ l√Ω. Khi nh·∫≠n ƒë∆∞·ª£c ph·∫£n h·ªìi t·ª´ server, frontend s·∫Ω x·ª≠ l√Ω JSON response ch·ª©a k·∫øt qu·∫£ d·ª± ƒëo√°n cho t·ª´ng ·∫£nh, bao g·ªìm l·ªõp d·ª± ƒëo√°n (cat ho·∫∑c dog), ƒë·ªô tin c·∫≠y (confidence), v√† chi ti·∫øt x√°c su·∫•t cho c·∫£ hai l·ªõp.

X·ª≠ l√Ω l·ªói: Frontend c√≥ c∆° ch·∫ø x·ª≠ l√Ω l·ªói t·ªët, hi·ªÉn th·ªã th√¥ng b√°o r√µ r√†ng khi c√≥ l·ªói x·∫£y ra (v√≠ d·ª•: file kh√¥ng h·ª£p l·ªá, server l·ªói, model ch∆∞a ƒë∆∞·ª£c load).

G·ª≠i request d·ª± ƒëo√°n
<!-- File: templates/index.html -->
<script>
    async function predictImage() {
        if (!selectedFiles.length) return;
        
        // Hi·ªÉn th·ªã loading
        const loading = document.getElementById('loading');
        const error = document.getElementById('error');
        const resultsContainer = document.getElementById('resultsContainer');
        loading.style.display = 'block';
        error.style.display = 'none';
        resultsContainer.innerHTML = '';
        
        // T·∫°o FormData v√† g·ª≠i request
        const formData = new FormData();
        selectedFiles.forEach(file => formData.append('files', file));
        
        try {
            const response = await fetch('/predict', {
                method: 'POST',
                body: formData
            });
            
            const data = await response.json();
            
            if (!response.ok) {
                throw new Error(data.error || 'C√≥ l·ªói x·∫£y ra');
            }
            
            if (!data.results || !data.results.length) {
                throw new Error('Kh√¥ng nh·∫≠n ƒë∆∞·ª£c k·∫øt qu·∫£ t·ª´ server');
            }
            
            // X·ª≠ l√Ω v√† hi·ªÉn th·ªã k·∫øt qu·∫£
            displayResults(data.results);
            
        } catch (err) {
            error.textContent = '‚ùå ' + err.message;
            error.style.display = 'block';
        } finally {
            loading.style.display = 'none';
        }
    }
</script>

3.5.3. Hi·ªÉn th·ªã k·∫øt qu·∫£ d·ª± ƒëo√°n v√† x√°c su·∫•t
Sau khi nh·∫≠n ƒë∆∞·ª£c k·∫øt qu·∫£ t·ª´ API `/predict`, frontend s·∫Ω hi·ªÉn th·ªã k·∫øt qu·∫£ d·ª± ƒëo√°n cho t·ª´ng ·∫£nh m·ªôt c√°ch tr·ª±c quan v√† d·ªÖ hi·ªÉu. M·ªói k·∫øt qu·∫£ ƒë∆∞·ª£c hi·ªÉn th·ªã trong m·ªôt card ri√™ng bi·ªát bao g·ªìm:
‚Ä¢	·∫¢nh g·ªëc ƒë√£ upload: Hi·ªÉn th·ªã ·∫£nh m√† ng∆∞·ªùi d√πng ƒë√£ ch·ªçn.
‚Ä¢	T√™n file: T√™n c·ªßa file ·∫£nh.
‚Ä¢	L·ªõp d·ª± ƒëo√°n: Hi·ªÉn th·ªã "M√àO" ho·∫∑c "CH√ì" k√®m theo emoji t∆∞∆°ng ·ª©ng (üê± ho·∫∑c üê∂).
‚Ä¢	ƒê·ªô tin c·∫≠y: Ph·∫ßn trƒÉm ƒë·ªô tin c·∫≠y c·ªßa d·ª± ƒëo√°n (v√≠ d·ª•: 85.32%).
‚Ä¢	Progress bar: Thanh ti·∫øn tr√¨nh tr·ª±c quan h√≥a ƒë·ªô tin c·∫≠y.
‚Ä¢	Chi ti·∫øt x√°c su·∫•t: Hi·ªÉn th·ªã x√°c su·∫•t cho c·∫£ hai l·ªõp (Cat v√† Dog) ƒë·ªÉ ng∆∞·ªùi d√πng c√≥ th·ªÉ so s√°nh.

K·∫øt qu·∫£ ƒë∆∞·ª£c hi·ªÉn th·ªã d∆∞·ªõi d·∫°ng grid responsive, t·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh s·ªë c·ªôt theo k√≠ch th∆∞·ªõc m√†n h√¨nh (desktop, tablet, mobile), ƒë·∫£m b·∫£o tr·∫£i nghi·ªám t·ªët tr√™n m·ªçi thi·∫øt b·ªã.

Hi·ªÉn th·ªã k·∫øt qu·∫£ d·ª± ƒëo√°n
<!-- File: templates/index.html -->
<script>
    function displayResults(results) {
        const resultsContainer = document.getElementById('resultsContainer');
        const resultsWrapper = document.getElementById('resultsWrapper');
        
        resultsContainer.innerHTML = '';
        
        results.forEach((item, idx) => {
            const emoji = item.class === 'cat' ? 'üê±' : 'üê∂';
            const label = item.class === 'cat' ? 'M√àO' : 'CH√ì';
            
            const card = document.createElement('div');
            card.className = 'result-card';
            card.innerHTML = `
                <img class="result-image" alt="${item.filename}">
                <div class="result-filename">${item.filename}</div>
                <div class="result-class">${emoji} ${label}</div>
                <div class="result-confidence">${item.confidence}%</div>
                <div class="progress-bar">
                    <div class="progress-fill" style="width: ${item.confidence}%;">
                        ${item.confidence}%
                    </div>
                </div>
                <div class="details">
                    <div class="detail-item">
                        <div class="detail-label">üê± M√®o</div>
                        <div class="detail-value">${item.details.cat}%</div>
                    </div>
                    <div class="detail-item">
                        <div class="detail-label">üê∂ Ch√≥</div>
                        <div class="detail-value">${item.details.dog}%</div>
                    </div>
                </div>
            `;
            
            // Load ·∫£nh v√†o card
            const reader = new FileReader();
            reader.onload = (e) => {
                card.querySelector('.result-image').src = e.target.result;
            };
            reader.readAsDataURL(selectedFiles[idx]);
            
            resultsContainer.appendChild(card);
        });
        
        resultsWrapper.style.display = 'block';
    }
</script>

<!-- CSS cho responsive grid -->
<style>
    .results-grid {
        display: grid;
        gap: 20px;
        grid-template-columns: repeat(auto-fit, minmax(240px, 1fr));
    }
    
    .result-card {
        background: #f9f9f9;
        border-radius: 8px;
        padding: 15px;
        text-align: center;
    }
    
    .result-image {
        width: 100%;
        height: 200px;
        object-fit: cover;
        border-radius: 6px;
        margin-bottom: 10px;
    }
    
    .result-class {
        font-size: 20px;
        font-weight: bold;
        margin: 10px 0;
        color: #333;
    }
    
    .result-confidence {
        font-size: 24px;
        font-weight: bold;
        color: #667eea;
        margin: 10px 0;
    }
    
    .progress-bar {
        width: 100%;
        height: 25px;
        background: #e0e0e0;
        border-radius: 12px;
        overflow: hidden;
        margin: 10px 0;
    }
    
    .progress-fill {
        height: 100%;
        background: linear-gradient(90deg, #667eea, #764ba2);
        display: flex;
        align-items: center;
        justify-content: center;
        color: white;
        font-weight: bold;
        transition: width 0.5s ease;
    }
</style>

3.6. K·∫øt qu·∫£ th·ª≠ nghi·ªám v√† ƒë√°nh gi√° hi·ªáu qu·∫£ h·ªá th·ªëng
Sau khi ho√†n th√†nh vi·ªác tri·ªÉn khai, h·ªá th·ªëng ƒë√£ ƒë∆∞·ª£c th·ª≠ nghi·ªám v√† ƒë√°nh gi√° tr√™n t·∫≠p validation v·ªõi c√°c k·∫øt qu·∫£ nh∆∞ sau:
‚Ä¢	Accuracy: Kho·∫£ng 80.38% - cho th·∫•y m√¥ h√¨nh c√≥ kh·∫£ nƒÉng ph√¢n lo·∫°i ƒë√∫ng kho·∫£ng 8/10 ·∫£nh.
‚Ä¢	Precision: Kho·∫£ng 80.54% - cho th·∫•y trong s·ªë c√°c d·ª± ƒëo√°n l√† Cat ho·∫∑c Dog, c√≥ kho·∫£ng 80.54% l√† ƒë√∫ng.
‚Ä¢	Recall: Kho·∫£ng 80.38% - cho th·∫•y m√¥ h√¨nh c√≥ th·ªÉ ph√°t hi·ªán ƒë∆∞·ª£c kho·∫£ng 80.38% s·ªë l∆∞·ª£ng Cat/Dog th·ª±c s·ª± trong t·∫≠p d·ªØ li·ªáu.
‚Ä¢	F1-Score: Kho·∫£ng 80.36% - ch·ªâ s·ªë c√¢n b·∫±ng gi·ªØa Precision v√† Recall.

ƒê·ªëi v·ªõi ·ª©ng d·ª•ng web:
‚Ä¢	H·ªá th·ªëng c√≥ th·ªÉ x·ª≠ l√Ω t·ªëi ƒëa 6 ·∫£nh c√πng l√∫c, gi√∫p tƒÉng tr·∫£i nghi·ªám ng∆∞·ªùi d√πng.
‚Ä¢	Th·ªùi gian d·ª± ƒëo√°n nhanh (th∆∞·ªùng d∆∞·ªõi 1 gi√¢y cho m·ªói ·∫£nh) nh·ªù batch processing.
‚Ä¢	Giao di·ªán tr·ª±c quan, d·ªÖ s·ª≠ d·ª•ng v·ªõi preview ·∫£nh v√† hi·ªÉn th·ªã k·∫øt qu·∫£ r√µ r√†ng.
‚Ä¢	X·ª≠ l√Ω l·ªói t·ªët v·ªõi c√°c th√¥ng b√°o r√µ r√†ng khi file kh√¥ng h·ª£p l·ªá ho·∫∑c model ch∆∞a ƒë∆∞·ª£c load.

3.7. ƒê·ªÅ xu·∫•t h∆∞·ªõng c·∫£i ti·∫øn v√† ph√°t tri·ªÉn trong t∆∞∆°ng lai
D·ª±a tr√™n k·∫øt qu·∫£ hi·ªán t·∫°i v√† c√°c h·∫°n ch·∫ø c·ªßa h·ªá th·ªëng, m·ªôt s·ªë h∆∞·ªõng c·∫£i ti·∫øn c√≥ th·ªÉ ƒë∆∞·ª£c ƒë·ªÅ xu·∫•t:
‚Ä¢	N√¢ng cao ƒë·ªô ch√≠nh x√°c m√¥ h√¨nh: S·ª≠ d·ª•ng Transfer Learning v·ªõi c√°c m√¥ h√¨nh pre-trained nh∆∞ VGG16, ResNet, ho·∫∑c EfficientNet ƒë·ªÉ t·∫≠n d·ª•ng c√°c ƒë·∫∑c tr∆∞ng ƒë√£ ƒë∆∞·ª£c h·ªçc t·ª´ d·ªØ li·ªáu l·ªõn (ImageNet). ƒêi·ªÅu n√†y c√≥ th·ªÉ gi√∫p n√¢ng accuracy l√™n tr√™n 90%.
‚Ä¢	TƒÉng c∆∞·ªùng d·ªØ li·ªáu: Thu th·∫≠p th√™m d·ªØ li·ªáu ·∫£nh v·ªõi nhi·ªÅu ƒëi·ªÅu ki·ªán kh√°c nhau (√°nh s√°ng y·∫øu, g√≥c ch·ª•p ƒë·∫∑c bi·ªát, c√°c gi·ªëng ch√≥/m√®o hi·∫øm) ƒë·ªÉ c·∫£i thi·ªán kh·∫£ nƒÉng t·ªïng qu√°t h√≥a.
‚Ä¢	M·ªü r·ªông ph√¢n lo·∫°i: Thay v√¨ ch·ªâ ph√¢n lo·∫°i Cat/Dog, c√≥ th·ªÉ m·ªü r·ªông ƒë·ªÉ ph√¢n lo·∫°i nhi·ªÅu lo·∫°i ƒë·ªông v·∫≠t kh√°c ho·∫∑c th·∫≠m ch√≠ ph√¢n lo·∫°i theo gi·ªëng (breed classification).
‚Ä¢	C·∫£i thi·ªán giao di·ªán: Th√™m t√≠nh nƒÉng drag-and-drop ƒë·ªÉ upload ·∫£nh, th√™m animation khi hi·ªÉn th·ªã k·∫øt qu·∫£, h·ªó tr·ª£ responsive t·ªët h∆°n cho mobile.
‚Ä¢	T·ªëi ∆∞u hi·ªáu su·∫•t: Tri·ªÉn khai model tr√™n GPU server ho·∫∑c s·ª≠ d·ª•ng TensorFlow Lite ƒë·ªÉ t·ªëi ∆∞u h√≥a inference tr√™n thi·∫øt b·ªã di ƒë·ªông. C√≥ th·ªÉ s·ª≠ d·ª•ng Redis ƒë·ªÉ cache k·∫øt qu·∫£ cho c√°c ·∫£nh ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω.
‚Ä¢	B·∫£o m·∫≠t: Th√™m x√°c th·ª±c ng∆∞·ªùi d√πng, gi·ªõi h·∫°n s·ªë l∆∞·ª£ng request, v√† x·ª≠ l√Ω t·ªët h∆°n c√°c t·∫•n c√¥ng nh∆∞ file upload attack.
‚Ä¢	Deployment: Tri·ªÉn khai l√™n cloud (AWS, Google Cloud, Azure) v·ªõi Docker containerization ƒë·ªÉ d·ªÖ d√†ng scale v√† qu·∫£n l√Ω.
